{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.autograd import Variable\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/home/raffaele/Documents/ml-project/src/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_utility import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.genfromtxt('/home/raffaele/Documents/ml-project/cup/ML-CUP20-TR.csv', delimiter=',', dtype=np.float64)\n",
    "X = data[:, 1:-2]\n",
    "y = data[:, -2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1524, 10)\n",
      "(1524, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xval, ytrain, yval = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split train set and Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = Xtrain.astype('float32')\n",
    "ytrain = ytrain.astype('float32')\n",
    "\n",
    "Xval = Xval.astype('float32')\n",
    "yval = yval.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self, num_units1, num_units2):\n",
    "        super(Net, self).__init__()\n",
    "        self.input_layer = nn.Linear(10,num_units1)\n",
    "        self.hidden1 = nn.Linear(num_units1, num_units2)\n",
    "        self.output = nn.Linear(num_units2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.tanh(self.input_layer(x))\n",
    "        x = torch.tanh(self.hidden1(x))\n",
    "        x = self.output(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MEE(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(MEE, self).__init__()\n",
    "\n",
    "    def forward(self, y_true, y_pred):\n",
    "#         return torch.mean(torch.linalg.norm(y_pred - y_true))\n",
    "#         return torch.mean(torch.cdist(y_true, y_pred, p=2))\n",
    "#         return torch.div(torch.sum(torch.pairwise_distance(y_true, y_pred)), len(y_true))\n",
    "        return torch.mean(torch.linalg.norm(y_true - y_pred, axis=1))\n",
    "#         return torch.div(torch.linalg.norm(y_pred - y_true, ord=None), len(y_true))\n",
    "#         return torch.div(torch.linalg.norm(y_pred - y_true), len(y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import euclidean_distances\n",
    "\n",
    "def mean_euclidean_error(y_true, y_pred):\n",
    "    assert y_true.shape == y_pred.shape\n",
    "#     return np.mean(np.linalg.norm(y_pred - y_true))\n",
    "#     return np.divide(np.linalg.norm(y - y_real), len(y_real))\n",
    "#     return np.mean(euclidean_distances(y_true, y_pred))\n",
    "    return np.mean(np.linalg.norm(y_true - y_pred, axis=1)) #utilizzare questa loss la prossima grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain1 = ytrain[:,0]\n",
    "ytrain2 = ytrain[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain1 = ytrain1.reshape(ytrain1.shape[0], 1)\n",
    "ytrain2 = ytrain2.reshape(ytrain2.shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1       \u001b[36m48.6404\u001b[0m       \u001b[32m46.5343\u001b[0m  0.0436\n",
      "      2       \u001b[36m46.7824\u001b[0m       \u001b[32m43.6384\u001b[0m  0.0413\n",
      "      3       \u001b[36m42.4935\u001b[0m       \u001b[32m37.4765\u001b[0m  0.0410\n",
      "      4       \u001b[36m35.2428\u001b[0m       \u001b[32m29.3425\u001b[0m  0.0394\n",
      "      5       \u001b[36m26.8025\u001b[0m       \u001b[32m20.6589\u001b[0m  0.0410\n",
      "      6       \u001b[36m18.9361\u001b[0m       \u001b[32m15.2965\u001b[0m  0.0418\n",
      "      7       \u001b[36m15.3428\u001b[0m       \u001b[32m12.5193\u001b[0m  0.0395\n",
      "      8       \u001b[36m12.3170\u001b[0m       \u001b[32m11.3177\u001b[0m  0.0383\n",
      "      9       \u001b[36m10.1365\u001b[0m        \u001b[32m8.3252\u001b[0m  0.0417\n",
      "     10        \u001b[36m8.4000\u001b[0m        \u001b[32m7.3700\u001b[0m  0.0420\n",
      "     11        \u001b[36m7.4198\u001b[0m        \u001b[32m6.5224\u001b[0m  0.0399\n",
      "     12        \u001b[36m6.4569\u001b[0m        \u001b[32m5.6712\u001b[0m  0.0386\n",
      "     13        \u001b[36m5.5787\u001b[0m        \u001b[32m5.2352\u001b[0m  0.0413\n",
      "     14        \u001b[36m4.9206\u001b[0m        \u001b[32m4.4158\u001b[0m  0.0395\n",
      "     15        \u001b[36m4.3892\u001b[0m        \u001b[32m4.2937\u001b[0m  0.0397\n",
      "     16        \u001b[36m3.9468\u001b[0m        \u001b[32m3.5711\u001b[0m  0.0391\n",
      "     17        \u001b[36m3.5727\u001b[0m        3.5814  0.0400\n",
      "     18        \u001b[36m3.3131\u001b[0m        \u001b[32m2.9599\u001b[0m  0.0404\n",
      "     19        \u001b[36m3.0303\u001b[0m        3.0055  0.0410\n",
      "     20        \u001b[36m2.8209\u001b[0m        2.9862  0.0403\n",
      "     21        \u001b[36m2.6392\u001b[0m        \u001b[32m2.6464\u001b[0m  0.0415\n",
      "     22        \u001b[36m2.4856\u001b[0m        \u001b[32m2.3308\u001b[0m  0.0434\n",
      "     23        \u001b[36m2.3112\u001b[0m        2.5551  0.0443\n",
      "     24        \u001b[36m2.2328\u001b[0m        2.4458  0.0445\n",
      "     25        \u001b[36m2.1446\u001b[0m        2.3318  0.0438\n",
      "     26        \u001b[36m2.0676\u001b[0m        \u001b[32m2.1721\u001b[0m  0.0456\n",
      "     27        \u001b[36m1.9982\u001b[0m        \u001b[32m2.0854\u001b[0m  0.0526\n",
      "     28        \u001b[36m1.9492\u001b[0m        2.3277  0.0452\n",
      "     29        \u001b[36m1.9257\u001b[0m        \u001b[32m2.0156\u001b[0m  0.0495\n",
      "     30        \u001b[36m1.8835\u001b[0m        2.2129  0.0461\n",
      "     31        \u001b[36m1.8620\u001b[0m        \u001b[32m1.9976\u001b[0m  0.0481\n",
      "     32        \u001b[36m1.8446\u001b[0m        2.0197  0.0455\n",
      "     33        \u001b[36m1.8087\u001b[0m        \u001b[32m1.9226\u001b[0m  0.0434\n",
      "     34        \u001b[36m1.8046\u001b[0m        1.9807  0.0434\n",
      "     35        \u001b[36m1.7833\u001b[0m        2.0851  0.0489\n",
      "     36        \u001b[36m1.7698\u001b[0m        \u001b[32m1.8374\u001b[0m  0.0510\n",
      "     37        \u001b[36m1.7573\u001b[0m        1.8602  0.0480\n",
      "     38        \u001b[36m1.7442\u001b[0m        2.1172  0.0500\n",
      "     39        1.7624        1.9310  0.0424\n",
      "     40        1.7574        2.0191  0.0455\n",
      "     41        \u001b[36m1.7311\u001b[0m        \u001b[32m1.8183\u001b[0m  0.0421\n",
      "     42        \u001b[36m1.7005\u001b[0m        2.0121  0.0442\n",
      "     43        1.7159        \u001b[32m1.8046\u001b[0m  0.0429\n",
      "     44        \u001b[36m1.6829\u001b[0m        1.8469  0.0449\n",
      "     45        1.6859        1.8383  0.0463\n",
      "     46        \u001b[36m1.6710\u001b[0m        1.9387  0.0430\n",
      "     47        1.6794        1.9135  0.0416\n",
      "     48        \u001b[36m1.6373\u001b[0m        1.8192  0.0445\n",
      "     49        \u001b[36m1.6308\u001b[0m        \u001b[32m1.7727\u001b[0m  0.0415\n",
      "     50        \u001b[36m1.6217\u001b[0m        1.7983  0.0386\n",
      "     51        \u001b[36m1.6133\u001b[0m        1.8120  0.0428\n",
      "     52        \u001b[36m1.6006\u001b[0m        1.8013  0.0419\n",
      "     53        1.6092        1.9006  0.0427\n",
      "     54        1.6050        1.9517  0.0425\n",
      "     55        1.6148        1.8908  0.0412\n",
      "     56        \u001b[36m1.5747\u001b[0m        1.9533  0.0417\n",
      "     57        1.5767        2.0390  0.0419\n",
      "     58        1.6083        1.8896  0.0378\n",
      "     59        \u001b[36m1.5659\u001b[0m        1.8639  0.0475\n",
      "     60        \u001b[36m1.5584\u001b[0m        1.8878  0.0402\n",
      "     61        \u001b[36m1.5499\u001b[0m        \u001b[32m1.7623\u001b[0m  0.0417\n",
      "     62        \u001b[36m1.5490\u001b[0m        1.9703  0.0398\n",
      "     63        1.5712        1.8653  0.0410\n",
      "     64        \u001b[36m1.5459\u001b[0m        \u001b[32m1.7562\u001b[0m  0.0445\n",
      "     65        \u001b[36m1.5448\u001b[0m        1.8321  0.0423\n",
      "     66        \u001b[36m1.5382\u001b[0m        1.8597  0.0436\n",
      "     67        1.5537        1.9021  0.0427\n",
      "     68        1.5409        1.8521  0.0438\n",
      "     69        \u001b[36m1.5216\u001b[0m        1.7966  0.0438\n",
      "     70        1.5406        1.9241  0.0497\n",
      "     71        1.5289        1.8275  0.0432\n",
      "     72        1.5312        1.9444  0.0420\n",
      "     73        \u001b[36m1.5186\u001b[0m        1.8604  0.0454\n",
      "     74        1.5235        1.8318  0.0443\n",
      "     75        \u001b[36m1.5147\u001b[0m        1.8455  0.0450\n",
      "     76        1.5483        1.7947  0.0430\n",
      "     77        1.5280        2.0867  0.0426\n",
      "     78        1.5203        1.7950  0.0406\n",
      "     79        1.5233        1.8417  0.0434\n",
      "     80        1.5165        2.0800  0.0422\n",
      "     81        1.5222        1.7700  0.0440\n",
      "     82        \u001b[36m1.4927\u001b[0m        1.8647  0.0465\n",
      "     83        1.5281        2.0402  0.0546\n",
      "     84        1.5262        1.9730  0.0433\n",
      "     85        1.4988        1.8734  0.0440\n",
      "     86        \u001b[36m1.4887\u001b[0m        2.0053  0.0443\n",
      "     87        \u001b[36m1.4830\u001b[0m        2.0907  0.0423\n",
      "     88        1.4902        1.9427  0.0426\n",
      "     89        1.4977        1.8581  0.0431\n",
      "     90        \u001b[36m1.4810\u001b[0m        1.9504  0.0459\n",
      "     91        \u001b[36m1.4731\u001b[0m        1.9273  0.0419\n",
      "     92        1.4770        1.8595  0.0440\n",
      "     93        1.4763        1.8046  0.0475\n",
      "     94        1.4860        1.8169  0.0467\n",
      "     95        1.4791        1.9067  0.0421\n",
      "     96        \u001b[36m1.4577\u001b[0m        2.0516  0.0436\n",
      "     97        1.4792        1.8120  0.0408\n",
      "     98        1.4774        2.0675  0.0466\n",
      "     99        1.4766        1.9070  0.0498\n",
      "    100        \u001b[36m1.4535\u001b[0m        2.0615  0.0432\n",
      "    101        1.4560        1.9973  0.0404\n",
      "    102        1.4675        1.9190  0.0408\n",
      "    103        1.4594        1.9958  0.0404\n",
      "    104        \u001b[36m1.4419\u001b[0m        2.0708  0.0409\n",
      "    105        1.4787        1.7657  0.0426\n",
      "    106        1.4688        1.8728  0.0441\n",
      "    107        1.4488        1.9758  0.0384\n",
      "    108        1.4587        2.0353  0.0418\n",
      "    109        1.4464        1.9736  0.0395\n",
      "    110        \u001b[36m1.4350\u001b[0m        1.7753  0.0397\n",
      "    111        \u001b[36m1.4237\u001b[0m        1.8762  0.0395\n",
      "    112        1.4267        1.9579  0.0398\n",
      "    113        1.4308        1.8751  0.0393\n",
      "    114        1.4288        1.8631  0.0407\n",
      "    115        1.4313        2.0028  0.0390\n",
      "    116        1.4255        1.8759  0.0423\n",
      "    117        1.4341        1.9214  0.0418\n",
      "    118        1.4239        1.9628  0.0408\n",
      "    119        1.4263        1.8069  0.0401\n",
      "    120        \u001b[36m1.4053\u001b[0m        2.0375  0.0415\n",
      "    121        1.4210        1.8702  0.0406\n",
      "    122        1.4199        1.8625  0.0392\n",
      "    123        1.4183        1.9599  0.0415\n",
      "    124        1.4194        1.8549  0.0424\n",
      "    125        1.4143        2.0169  0.0417\n",
      "    126        1.4105        2.0126  0.0384\n",
      "    127        1.4099        1.9505  0.0406\n",
      "    128        1.4140        1.9032  0.0412\n",
      "    129        \u001b[36m1.4024\u001b[0m        1.8191  0.0405\n",
      "    130        \u001b[36m1.3984\u001b[0m        2.0061  0.0397\n",
      "    131        1.4048        1.9290  0.0380\n",
      "    132        1.4012        2.1172  0.0394\n",
      "    133        1.4346        1.9122  0.0405\n",
      "    134        \u001b[36m1.3894\u001b[0m        1.8315  0.0417\n",
      "    135        1.4053        1.9149  0.0405\n",
      "    136        1.4072        1.9889  0.0410\n",
      "    137        1.4016        1.9125  0.0393\n",
      "    138        1.3974        1.8712  0.0436\n",
      "    139        1.3948        2.0400  0.0393\n",
      "    140        1.3914        1.8633  0.0386\n",
      "    141        1.4118        2.0714  0.0407\n",
      "    142        1.3928        1.9504  0.0403\n",
      "    143        \u001b[36m1.3695\u001b[0m        1.8197  0.0385\n",
      "    144        1.4022        2.0032  0.0398\n",
      "    145        1.3845        1.8346  0.0384\n",
      "    146        1.4059        2.1199  0.0406\n",
      "    147        1.4335        2.0123  0.0393\n",
      "    148        1.3760        2.1174  0.0391\n",
      "    149        1.3935        1.9597  0.0388\n",
      "    150        1.4110        1.9930  0.0397\n",
      "    151        1.4008        1.9998  0.0383\n",
      "    152        1.3879        1.9878  0.0427\n",
      "    153        1.4003        2.0427  0.0387\n",
      "    154        1.3847        1.8633  0.0384\n",
      "    155        1.4117        1.9482  0.0393\n",
      "    156        1.3890        2.1982  0.0382\n",
      "    157        1.3945        1.8681  0.0389\n",
      "    158        1.3951        1.8788  0.0392\n",
      "    159        1.3897        1.9211  0.0455\n",
      "    160        1.3764        1.9147  0.0391\n",
      "    161        1.4026        1.8988  0.0409\n",
      "    162        \u001b[36m1.3656\u001b[0m        2.0314  0.0391\n",
      "    163        \u001b[36m1.3532\u001b[0m        1.9435  0.0406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    164        1.3989        1.8273  0.0405\n",
      "    165        1.3815        1.9197  0.0408\n",
      "    166        1.3886        1.8898  0.0377\n",
      "    167        1.3974        1.8881  0.0377\n",
      "    168        1.3598        1.8761  0.0401\n",
      "    169        1.3952        1.8500  0.0378\n",
      "    170        1.3547        2.0516  0.0382\n",
      "    171        1.3645        2.1404  0.0385\n",
      "    172        1.4031        2.0823  0.0465\n",
      "    173        1.3700        2.0578  0.0392\n",
      "    174        1.3837        1.8706  0.0400\n",
      "    175        1.3688        1.9458  0.0395\n",
      "    176        1.4032        1.9667  0.0395\n",
      "    177        1.3555        1.9971  0.0403\n",
      "    178        1.3711        1.8335  0.0374\n",
      "    179        1.3708        1.8884  0.0380\n",
      "    180        \u001b[36m1.3473\u001b[0m        1.9794  0.0377\n",
      "    181        1.3699        2.2296  0.0392\n",
      "    182        1.3730        1.9861  0.0380\n",
      "    183        1.3485        2.0988  0.0380\n",
      "    184        1.3740        1.8557  0.0391\n",
      "    185        1.3734        1.9031  0.0397\n",
      "    186        1.3540        1.9779  0.0384\n",
      "    187        1.3513        1.9536  0.0375\n",
      "    188        \u001b[36m1.3473\u001b[0m        1.8556  0.0380\n",
      "    189        1.3742        2.0287  0.0380\n",
      "    190        1.3559        2.1130  0.0395\n",
      "    191        \u001b[36m1.3278\u001b[0m        1.9624  0.0390\n",
      "    192        1.3605        2.0152  0.0385\n",
      "    193        1.3463        2.1088  0.0384\n",
      "    194        1.3530        1.9847  0.0381\n",
      "    195        1.3629        1.8766  0.0396\n",
      "    196        1.3566        1.8554  0.0383\n",
      "    197        \u001b[36m1.3249\u001b[0m        2.1530  0.0398\n",
      "    198        1.3487        2.1179  0.0400\n",
      "    199        1.3457        2.0483  0.0394\n",
      "    200        1.3671        2.0290  0.0388\n",
      "    201        1.3426        1.9831  0.0382\n",
      "    202        \u001b[36m1.3144\u001b[0m        2.0108  0.0386\n",
      "    203        1.3593        1.9740  0.0380\n",
      "    204        1.3620        2.0445  0.0381\n",
      "    205        1.3433        2.3199  0.0382\n",
      "    206        1.3468        2.1010  0.0385\n",
      "    207        1.3366        1.8972  0.0386\n",
      "    208        1.3540        2.1437  0.0382\n",
      "    209        1.3303        1.9096  0.0382\n",
      "    210        1.3562        2.2741  0.0384\n",
      "    211        1.3371        2.0364  0.0402\n",
      "    212        1.3695        1.9463  0.0377\n",
      "    213        1.3668        2.0505  0.0380\n",
      "    214        1.3166        1.9856  0.0396\n",
      "    215        1.3290        1.9433  0.0381\n",
      "    216        1.3565        1.9743  0.0382\n",
      "    217        1.3183        2.0138  0.0399\n",
      "    218        1.3429        1.8973  0.0405\n",
      "    219        \u001b[36m1.3131\u001b[0m        2.0694  0.0426\n",
      "    220        \u001b[36m1.3089\u001b[0m        1.9764  0.0389\n",
      "    221        1.3175        1.8509  0.0382\n",
      "    222        1.3279        2.2621  0.0383\n",
      "    223        1.3324        1.9484  0.0398\n",
      "    224        1.3396        2.0955  0.0397\n",
      "    225        \u001b[36m1.3030\u001b[0m        1.9896  0.0420\n",
      "    226        \u001b[36m1.3008\u001b[0m        1.8874  0.0394\n",
      "    227        1.3078        1.8669  0.0375\n",
      "    228        1.3175        2.1160  0.0403\n",
      "    229        1.3212        1.9676  0.0398\n",
      "    230        \u001b[36m1.2963\u001b[0m        1.9865  0.0384\n",
      "    231        1.3253        2.1078  0.0397\n",
      "    232        1.3582        1.8632  0.0423\n",
      "    233        1.3187        2.1334  0.0401\n",
      "    234        1.3392        1.8956  0.0401\n",
      "    235        \u001b[36m1.2782\u001b[0m        2.1060  0.0423\n",
      "    236        1.3558        2.0997  0.0412\n",
      "    237        1.3237        2.1442  0.0411\n",
      "    238        1.3143        2.1629  0.0404\n",
      "    239        1.3339        1.9572  0.0421\n",
      "    240        1.3311        2.3529  0.0395\n",
      "    241        1.3730        1.9596  0.0392\n",
      "    242        1.2956        1.9959  0.0378\n",
      "    243        1.3027        1.9365  0.0384\n",
      "    244        1.3328        2.0603  0.0385\n",
      "    245        1.3036        2.3477  0.0393\n",
      "    246        1.3393        2.1083  0.0380\n",
      "    247        1.3311        2.0252  0.0391\n",
      "    248        1.2894        1.9123  0.0390\n",
      "    249        1.3263        1.9888  0.0385\n",
      "    250        1.2925        2.2185  0.0387\n",
      "    251        1.2891        1.9846  0.0397\n",
      "    252        1.3050        1.9454  0.0392\n",
      "    253        1.3420        2.0188  0.0379\n",
      "    254        1.3139        1.9510  0.0376\n",
      "    255        1.2812        2.0436  0.0390\n",
      "    256        1.3081        1.9944  0.0418\n",
      "    257        1.2867        2.1291  0.0400\n",
      "    258        1.3299        1.9530  0.0420\n",
      "    259        1.2858        2.2150  0.0414\n",
      "    260        1.2803        2.0097  0.0402\n",
      "    261        1.3118        1.9987  0.0394\n",
      "    262        1.2935        1.9582  0.0389\n",
      "    263        1.3056        1.9228  0.0418\n",
      "    264        1.2788        2.2115  0.0396\n",
      "    265        1.3128        2.1276  0.0395\n",
      "    266        1.3135        1.9246  0.0400\n",
      "    267        1.2931        2.2305  0.0391\n",
      "    268        1.3340        2.1464  0.0384\n",
      "    269        \u001b[36m1.2735\u001b[0m        1.9973  0.0378\n",
      "    270        1.2736        1.9305  0.0396\n",
      "    271        1.2902        2.0985  0.0389\n",
      "    272        1.2846        2.0392  0.0384\n",
      "    273        \u001b[36m1.2714\u001b[0m        2.1520  0.0393\n",
      "    274        1.3182        1.8777  0.0392\n",
      "    275        \u001b[36m1.2660\u001b[0m        1.9070  0.0400\n",
      "    276        1.2941        1.9475  0.0384\n",
      "    277        1.3061        2.0884  0.0391\n",
      "    278        1.2673        1.9206  0.0397\n",
      "    279        \u001b[36m1.2605\u001b[0m        2.5081  0.0391\n",
      "    280        1.3270        1.9821  0.0381\n",
      "    281        1.2967        2.0224  0.0409\n",
      "    282        1.3030        2.1762  0.0383\n",
      "    283        1.2856        1.9417  0.0394\n",
      "    284        1.2672        1.9956  0.0445\n",
      "    285        1.2619        2.1059  0.0415\n",
      "    286        1.2631        2.0094  0.0417\n",
      "    287        1.2919        1.9404  0.0377\n",
      "    288        \u001b[36m1.2589\u001b[0m        1.9101  0.0390\n",
      "    289        \u001b[36m1.2559\u001b[0m        2.0553  0.0391\n",
      "    290        1.2954        2.0595  0.0388\n",
      "    291        1.2740        1.9921  0.0398\n",
      "    292        1.2731        1.9586  0.0391\n",
      "    293        1.2762        1.9758  0.0410\n",
      "    294        1.2638        2.1050  0.0420\n",
      "    295        1.2651        2.1313  0.0423\n",
      "    296        1.2974        1.9934  0.0403\n",
      "    297        1.3130        2.2219  0.0395\n",
      "    298        1.3309        1.9001  0.0387\n",
      "    299        1.2858        2.1585  0.0399\n",
      "    300        1.2634        1.9767  0.0382\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.regressor.NeuralNetRegressor'>[initialized](\n",
       "  module_=Net(\n",
       "    (input_layer): Linear(in_features=10, out_features=20, bias=True)\n",
       "    (hidden1): Linear(in_features=20, out_features=10, bias=True)\n",
       "    (output): Linear(in_features=10, out_features=1, bias=True)\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skorch import NeuralNetRegressor\n",
    "test_net1 = Net(20,10)\n",
    "# test_net1.apply(init_weights)\n",
    "nett1 = NeuralNetRegressor(test_net1, max_epochs=300,\n",
    "                          lr=0.01,\n",
    "                          batch_size=64,\n",
    "                          optimizer=optim.SGD,\n",
    "                          optimizer__momentum=0.8,\n",
    "                          optimizer__weight_decay=0.0001,\n",
    "                          optimizer__nesterov = True,\n",
    "                          criterion=MEE)\n",
    "# Training\n",
    "nett1.fit(Xtrain, ytrain1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1       \u001b[36m28.4561\u001b[0m       \u001b[32m27.3185\u001b[0m  0.0434\n",
      "      2       \u001b[36m27.7962\u001b[0m       \u001b[32m26.4630\u001b[0m  0.0584\n",
      "      3       \u001b[36m26.7610\u001b[0m       \u001b[32m25.1262\u001b[0m  0.0359\n",
      "      4       \u001b[36m25.1215\u001b[0m       \u001b[32m23.0485\u001b[0m  0.0352\n",
      "      5       \u001b[36m22.7779\u001b[0m       \u001b[32m20.5262\u001b[0m  0.0340\n",
      "      6       \u001b[36m20.1774\u001b[0m       \u001b[32m18.0641\u001b[0m  0.0444\n",
      "      7       \u001b[36m17.7030\u001b[0m       \u001b[32m15.7461\u001b[0m  0.0685\n",
      "      8       \u001b[36m15.4561\u001b[0m       \u001b[32m13.7089\u001b[0m  0.0498\n",
      "      9       \u001b[36m13.4358\u001b[0m       \u001b[32m11.7989\u001b[0m  0.0501\n",
      "     10       \u001b[36m11.3876\u001b[0m        \u001b[32m9.5414\u001b[0m  0.0530\n",
      "     11        \u001b[36m9.1093\u001b[0m        \u001b[32m7.3435\u001b[0m  0.0478\n",
      "     12        \u001b[36m7.1509\u001b[0m        \u001b[32m5.7389\u001b[0m  0.0508\n",
      "     13        \u001b[36m5.7827\u001b[0m        \u001b[32m4.7779\u001b[0m  0.0572\n",
      "     14        \u001b[36m4.9276\u001b[0m        \u001b[32m4.1590\u001b[0m  0.0546\n",
      "     15        \u001b[36m4.4601\u001b[0m        \u001b[32m3.8322\u001b[0m  0.0555\n",
      "     16        \u001b[36m4.1936\u001b[0m        \u001b[32m3.6748\u001b[0m  0.0551\n",
      "     17        \u001b[36m4.0203\u001b[0m        \u001b[32m3.5548\u001b[0m  0.0606\n",
      "     18        \u001b[36m3.7923\u001b[0m        \u001b[32m3.2739\u001b[0m  0.0523\n",
      "     19        \u001b[36m3.4510\u001b[0m        \u001b[32m3.0908\u001b[0m  0.0648\n",
      "     20        \u001b[36m3.1372\u001b[0m        \u001b[32m2.9460\u001b[0m  0.0586\n",
      "     21        \u001b[36m2.9445\u001b[0m        \u001b[32m2.8175\u001b[0m  0.0573\n",
      "     22        \u001b[36m2.7997\u001b[0m        \u001b[32m2.6954\u001b[0m  0.0653\n",
      "     23        \u001b[36m2.6551\u001b[0m        \u001b[32m2.5888\u001b[0m  0.0602\n",
      "     24        \u001b[36m2.5435\u001b[0m        \u001b[32m2.4661\u001b[0m  0.0528\n",
      "     25        \u001b[36m2.4493\u001b[0m        \u001b[32m2.3772\u001b[0m  0.0551\n",
      "     26        \u001b[36m2.3767\u001b[0m        \u001b[32m2.3654\u001b[0m  0.0456\n",
      "     27        \u001b[36m2.3280\u001b[0m        \u001b[32m2.3207\u001b[0m  0.0588\n",
      "     28        \u001b[36m2.2719\u001b[0m        \u001b[32m2.2610\u001b[0m  0.0599\n",
      "     29        \u001b[36m2.2278\u001b[0m        \u001b[32m2.2282\u001b[0m  0.0539\n",
      "     30        \u001b[36m2.1971\u001b[0m        \u001b[32m2.1939\u001b[0m  0.0497\n",
      "     31        \u001b[36m2.1767\u001b[0m        \u001b[32m2.1645\u001b[0m  0.0510\n",
      "     32        \u001b[36m2.1531\u001b[0m        \u001b[32m2.1491\u001b[0m  0.0453\n",
      "     33        \u001b[36m2.1297\u001b[0m        \u001b[32m2.1440\u001b[0m  0.0464\n",
      "     34        \u001b[36m2.1140\u001b[0m        \u001b[32m2.1436\u001b[0m  0.0470\n",
      "     35        \u001b[36m2.0971\u001b[0m        2.1778  0.0455\n",
      "     36        \u001b[36m2.0859\u001b[0m        \u001b[32m2.1361\u001b[0m  0.0540\n",
      "     37        \u001b[36m2.0824\u001b[0m        2.1842  0.0472\n",
      "     38        \u001b[36m2.0672\u001b[0m        2.1632  0.0544\n",
      "     39        \u001b[36m2.0586\u001b[0m        2.1588  0.0546\n",
      "     40        \u001b[36m2.0407\u001b[0m        2.1725  0.0494\n",
      "     41        \u001b[36m2.0367\u001b[0m        2.1619  0.0515\n",
      "     42        \u001b[36m2.0361\u001b[0m        2.2089  0.0490\n",
      "     43        \u001b[36m2.0250\u001b[0m        2.1406  0.0547\n",
      "     44        \u001b[36m2.0218\u001b[0m        2.2099  0.0577\n",
      "     45        \u001b[36m2.0209\u001b[0m        2.1882  0.0509\n",
      "     46        \u001b[36m2.0067\u001b[0m        2.1757  0.0554\n",
      "     47        \u001b[36m2.0022\u001b[0m        2.1985  0.0563\n",
      "     48        \u001b[36m1.9952\u001b[0m        2.2276  0.0459\n",
      "     49        1.9969        2.2346  0.0528\n",
      "     50        \u001b[36m1.9865\u001b[0m        2.1937  0.0568\n",
      "     51        \u001b[36m1.9818\u001b[0m        2.1827  0.0509\n",
      "     52        \u001b[36m1.9731\u001b[0m        2.1834  0.0428\n",
      "     53        \u001b[36m1.9698\u001b[0m        2.1867  0.0612\n",
      "     54        1.9719        2.2333  0.0541\n",
      "     55        1.9759        2.2380  0.0506\n",
      "     56        \u001b[36m1.9689\u001b[0m        2.2217  0.0542\n",
      "     57        \u001b[36m1.9557\u001b[0m        2.2414  0.0515\n",
      "     58        1.9632        2.2160  0.0514\n",
      "     59        \u001b[36m1.9548\u001b[0m        2.1909  0.0435\n",
      "     60        \u001b[36m1.9429\u001b[0m        2.2550  0.0633\n",
      "     61        1.9457        2.1992  0.0609\n",
      "     62        \u001b[36m1.9388\u001b[0m        2.1730  0.0525\n",
      "     63        \u001b[36m1.9322\u001b[0m        2.2337  0.0496\n",
      "     64        \u001b[36m1.9302\u001b[0m        2.2577  0.0450\n",
      "     65        1.9341        2.2731  0.0491\n",
      "     66        \u001b[36m1.9235\u001b[0m        2.2464  0.0594\n",
      "     67        \u001b[36m1.9171\u001b[0m        2.2376  0.0446\n",
      "     68        1.9190        2.2319  0.0512\n",
      "     69        \u001b[36m1.9088\u001b[0m        2.2105  0.0426\n",
      "     70        1.9132        2.2238  0.0507\n",
      "     71        1.9092        2.2361  0.0626\n",
      "     72        \u001b[36m1.9038\u001b[0m        2.2406  0.0480\n",
      "     73        1.9039        2.2060  0.0517\n",
      "     74        \u001b[36m1.8988\u001b[0m        2.2109  0.0462\n",
      "     75        1.9023        2.2185  0.0483\n",
      "     76        \u001b[36m1.8932\u001b[0m        2.2097  0.0399\n",
      "     77        \u001b[36m1.8903\u001b[0m        2.2017  0.0497\n",
      "     78        \u001b[36m1.8876\u001b[0m        2.1967  0.0475\n",
      "     79        \u001b[36m1.8821\u001b[0m        2.2052  0.0435\n",
      "     80        \u001b[36m1.8759\u001b[0m        2.1978  0.0502\n",
      "     81        1.8785        2.2267  0.0448\n",
      "     82        \u001b[36m1.8722\u001b[0m        2.2147  0.0499\n",
      "     83        \u001b[36m1.8677\u001b[0m        2.2116  0.0463\n",
      "     84        \u001b[36m1.8666\u001b[0m        2.1952  0.0496\n",
      "     85        \u001b[36m1.8591\u001b[0m        2.1886  0.0558\n",
      "     86        \u001b[36m1.8577\u001b[0m        2.1959  0.0526\n",
      "     87        1.8581        2.1926  0.0457\n",
      "     88        \u001b[36m1.8523\u001b[0m        2.1929  0.0596\n",
      "     89        \u001b[36m1.8434\u001b[0m        2.1830  0.0610\n",
      "     90        1.8437        2.2122  0.0590\n",
      "     91        1.8443        2.1866  0.0572\n",
      "     92        \u001b[36m1.8345\u001b[0m        2.2034  0.0665\n",
      "     93        \u001b[36m1.8335\u001b[0m        2.1834  0.0659\n",
      "     94        \u001b[36m1.8320\u001b[0m        2.1869  0.0456\n",
      "     95        1.8328        2.1828  0.0470\n",
      "     96        \u001b[36m1.8253\u001b[0m        2.1937  0.0491\n",
      "     97        \u001b[36m1.8251\u001b[0m        2.1834  0.0453\n",
      "     98        \u001b[36m1.8219\u001b[0m        2.1893  0.0453\n",
      "     99        \u001b[36m1.8143\u001b[0m        2.2211  0.0483\n",
      "    100        1.8312        2.1869  0.0548\n",
      "    101        1.8181        2.1865  0.0446\n",
      "    102        1.8147        2.2309  0.0559\n",
      "    103        1.8236        2.2078  0.0482\n",
      "    104        \u001b[36m1.8133\u001b[0m        2.2042  0.0569\n",
      "    105        \u001b[36m1.8082\u001b[0m        2.2197  0.0553\n",
      "    106        1.8144        2.1818  0.0437\n",
      "    107        \u001b[36m1.8053\u001b[0m        2.2165  0.0410\n",
      "    108        \u001b[36m1.8033\u001b[0m        2.2115  0.0429\n",
      "    109        \u001b[36m1.7955\u001b[0m        2.1897  0.0427\n",
      "    110        \u001b[36m1.7954\u001b[0m        2.2267  0.0473\n",
      "    111        1.8110        2.2229  0.0413\n",
      "    112        \u001b[36m1.7939\u001b[0m        2.2592  0.0464\n",
      "    113        1.8117        2.2531  0.0421\n",
      "    114        1.7959        2.2114  0.0438\n",
      "    115        \u001b[36m1.7865\u001b[0m        2.2359  0.0447\n",
      "    116        \u001b[36m1.7861\u001b[0m        2.2370  0.0370\n",
      "    117        1.7876        2.2450  0.0520\n",
      "    118        1.7871        2.2422  0.0409\n",
      "    119        \u001b[36m1.7778\u001b[0m        2.2217  0.0513\n",
      "    120        1.7820        2.2406  0.0490\n",
      "    121        1.7785        2.2075  0.0566\n",
      "    122        \u001b[36m1.7688\u001b[0m        2.2278  0.0565\n",
      "    123        1.7752        2.2662  0.0484\n",
      "    124        1.7857        2.2388  0.0476\n",
      "    125        1.7697        2.2507  0.0497\n",
      "    126        \u001b[36m1.7676\u001b[0m        2.2591  0.0564\n",
      "    127        1.7685        2.2531  0.0730\n",
      "    128        1.7679        2.2474  0.0708\n",
      "    129        \u001b[36m1.7672\u001b[0m        2.2352  0.0562\n",
      "    130        \u001b[36m1.7575\u001b[0m        2.2651  0.0712\n",
      "    131        1.7654        2.2441  0.0673\n",
      "    132        1.7595        2.2365  0.0494\n",
      "    133        \u001b[36m1.7496\u001b[0m        2.2176  0.0631\n",
      "    134        \u001b[36m1.7460\u001b[0m        2.2422  0.0495\n",
      "    135        1.7525        2.2930  0.0443\n",
      "    136        1.7621        2.2652  0.0419\n",
      "    137        \u001b[36m1.7448\u001b[0m        2.2733  0.0431\n",
      "    138        1.7584        2.2457  0.0508\n",
      "    139        \u001b[36m1.7399\u001b[0m        2.2134  0.0459\n",
      "    140        1.7407        2.2585  0.0548\n",
      "    141        \u001b[36m1.7388\u001b[0m        2.2543  0.0465\n",
      "    142        \u001b[36m1.7381\u001b[0m        2.2425  0.0462\n",
      "    143        \u001b[36m1.7324\u001b[0m        2.2505  0.0544\n",
      "    144        1.7345        2.2596  0.0477\n",
      "    145        \u001b[36m1.7315\u001b[0m        2.2623  0.0519\n",
      "    146        \u001b[36m1.7293\u001b[0m        2.2839  0.0391\n",
      "    147        \u001b[36m1.7277\u001b[0m        2.2713  0.0500\n",
      "    148        1.7305        2.2725  0.0479\n",
      "    149        1.7277        2.2839  0.0470\n",
      "    150        \u001b[36m1.7224\u001b[0m        2.2535  0.0429\n",
      "    151        \u001b[36m1.7208\u001b[0m        2.2928  0.0478\n",
      "    152        1.7273        2.2885  0.0613\n",
      "    153        \u001b[36m1.7187\u001b[0m        2.2887  0.0567\n",
      "    154        \u001b[36m1.7178\u001b[0m        2.2732  0.0482\n",
      "    155        \u001b[36m1.7171\u001b[0m        2.2993  0.0539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    156        1.7209        2.2494  0.0585\n",
      "    157        1.7173        2.2822  0.0453\n",
      "    158        \u001b[36m1.7097\u001b[0m        2.2848  0.0443\n",
      "    159        \u001b[36m1.7087\u001b[0m        2.2827  0.0448\n",
      "    160        \u001b[36m1.7045\u001b[0m        2.2887  0.0487\n",
      "    161        1.7106        2.2949  0.0435\n",
      "    162        1.7131        2.3121  0.0466\n",
      "    163        1.7085        2.3274  0.0407\n",
      "    164        1.7092        2.2846  0.0417\n",
      "    165        \u001b[36m1.7022\u001b[0m        2.2960  0.0590\n",
      "    166        \u001b[36m1.6937\u001b[0m        2.2774  0.0387\n",
      "    167        1.6986        2.3530  0.0460\n",
      "    168        1.7056        2.2897  0.0462\n",
      "    169        1.6963        2.3501  0.0487\n",
      "    170        1.6960        2.2975  0.0586\n",
      "    171        \u001b[36m1.6936\u001b[0m        2.3099  0.0591\n",
      "    172        \u001b[36m1.6906\u001b[0m        2.3397  0.0469\n",
      "    173        \u001b[36m1.6902\u001b[0m        2.3083  0.0539\n",
      "    174        \u001b[36m1.6864\u001b[0m        2.3139  0.0436\n",
      "    175        \u001b[36m1.6789\u001b[0m        2.3022  0.0410\n",
      "    176        1.6835        2.3353  0.0403\n",
      "    177        \u001b[36m1.6786\u001b[0m        2.3150  0.0381\n",
      "    178        1.6842        2.3384  0.0385\n",
      "    179        1.6806        2.3320  0.0408\n",
      "    180        \u001b[36m1.6739\u001b[0m        2.3223  0.0471\n",
      "    181        \u001b[36m1.6737\u001b[0m        2.3406  0.0511\n",
      "    182        1.6741        2.3210  0.0513\n",
      "    183        \u001b[36m1.6665\u001b[0m        2.3637  0.0530\n",
      "    184        1.6763        2.3292  0.0494\n",
      "    185        1.6710        2.3554  0.0541\n",
      "    186        1.6673        2.3078  0.0520\n",
      "    187        \u001b[36m1.6614\u001b[0m        2.3482  0.0452\n",
      "    188        1.6664        2.2905  0.0600\n",
      "    189        1.6643        2.3455  0.0499\n",
      "    190        \u001b[36m1.6605\u001b[0m        2.3746  0.0545\n",
      "    191        1.6611        2.3328  0.0619\n",
      "    192        \u001b[36m1.6504\u001b[0m        2.3459  0.0524\n",
      "    193        1.6596        2.3348  0.0496\n",
      "    194        1.6507        2.3314  0.0541\n",
      "    195        1.6512        2.3324  0.0503\n",
      "    196        1.6520        2.3095  0.0541\n",
      "    197        1.6532        2.3585  0.0508\n",
      "    198        1.6523        2.2875  0.0711\n",
      "    199        \u001b[36m1.6458\u001b[0m        2.3325  0.0730\n",
      "    200        \u001b[36m1.6357\u001b[0m        2.2946  0.0606\n",
      "    201        1.6427        2.3050  0.0594\n",
      "    202        1.6363        2.3302  0.0567\n",
      "    203        \u001b[36m1.6310\u001b[0m        2.3270  0.0437\n",
      "    204        \u001b[36m1.6270\u001b[0m        2.3577  0.0529\n",
      "    205        1.6408        2.3295  0.0425\n",
      "    206        1.6315        2.3293  0.0480\n",
      "    207        \u001b[36m1.6255\u001b[0m        2.3445  0.0494\n",
      "    208        1.6278        2.3257  0.0440\n",
      "    209        \u001b[36m1.6219\u001b[0m        2.2806  0.0621\n",
      "    210        1.6280        2.3316  0.0509\n",
      "    211        \u001b[36m1.6207\u001b[0m        2.2958  0.0586\n",
      "    212        1.6210        2.3385  0.0556\n",
      "    213        1.6222        2.2948  0.0821\n",
      "    214        \u001b[36m1.6168\u001b[0m        2.2904  0.0714\n",
      "    215        \u001b[36m1.6139\u001b[0m        2.3111  0.0546\n",
      "    216        \u001b[36m1.6138\u001b[0m        2.3117  0.0427\n",
      "    217        \u001b[36m1.6063\u001b[0m        2.3361  0.0496\n",
      "    218        1.6118        2.3321  0.0450\n",
      "    219        1.6118        2.2896  0.0514\n",
      "    220        \u001b[36m1.6046\u001b[0m        2.3140  0.0398\n",
      "    221        \u001b[36m1.6002\u001b[0m        2.3098  0.0524\n",
      "    222        1.6038        2.3008  0.0459\n",
      "    223        \u001b[36m1.5973\u001b[0m        2.3261  0.0487\n",
      "    224        1.6010        2.3299  0.0579\n",
      "    225        1.6024        2.3345  0.0419\n",
      "    226        1.5980        2.2690  0.0424\n",
      "    227        \u001b[36m1.5874\u001b[0m        2.3239  0.0459\n",
      "    228        1.5904        2.3064  0.0566\n",
      "    229        1.5924        2.3171  0.0463\n",
      "    230        \u001b[36m1.5848\u001b[0m        2.2871  0.0398\n",
      "    231        \u001b[36m1.5830\u001b[0m        2.3333  0.0494\n",
      "    232        1.5853        2.2803  0.0534\n",
      "    233        1.5891        2.2840  0.0391\n",
      "    234        \u001b[36m1.5808\u001b[0m        2.2855  0.0440\n",
      "    235        \u001b[36m1.5776\u001b[0m        2.2847  0.0419\n",
      "    236        \u001b[36m1.5740\u001b[0m        2.3472  0.0370\n",
      "    237        1.5831        2.3302  0.0427\n",
      "    238        1.5777        2.2771  0.0344\n",
      "    239        1.5817        2.3125  0.0396\n",
      "    240        \u001b[36m1.5726\u001b[0m        2.3267  0.0556\n",
      "    241        1.5778        2.2980  0.0646\n",
      "    242        1.5813        2.3258  0.0466\n",
      "    243        1.5738        2.2896  0.0509\n",
      "    244        \u001b[36m1.5700\u001b[0m        2.3029  0.0489\n",
      "    245        \u001b[36m1.5647\u001b[0m        2.2824  0.0480\n",
      "    246        1.5703        2.2860  0.0682\n",
      "    247        \u001b[36m1.5600\u001b[0m        2.3123  0.0545\n",
      "    248        1.5637        2.2925  0.0748\n",
      "    249        \u001b[36m1.5567\u001b[0m        2.2962  0.0641\n",
      "    250        \u001b[36m1.5556\u001b[0m        2.2908  0.0534\n",
      "    251        1.5658        2.2968  0.0352\n",
      "    252        1.5591        2.3059  0.0502\n",
      "    253        1.5574        2.2878  0.0539\n",
      "    254        1.5637        2.2956  0.0440\n",
      "    255        1.5612        2.3034  0.0499\n",
      "    256        \u001b[36m1.5525\u001b[0m        2.2781  0.0497\n",
      "    257        \u001b[36m1.5450\u001b[0m        2.2905  0.0579\n",
      "    258        1.5490        2.2916  0.0464\n",
      "    259        1.5735        2.2999  0.0472\n",
      "    260        \u001b[36m1.5416\u001b[0m        2.3057  0.0610\n",
      "    261        1.5577        2.3082  0.0522\n",
      "    262        1.5426        2.2567  0.0683\n",
      "    263        1.5549        2.2990  0.0673\n",
      "    264        1.5439        2.2723  0.0575\n",
      "    265        1.5709        2.2725  0.0430\n",
      "    266        \u001b[36m1.5379\u001b[0m        2.2700  0.0384\n",
      "    267        1.5670        2.2972  0.0374\n",
      "    268        \u001b[36m1.5365\u001b[0m        2.2822  0.0365\n",
      "    269        1.5371        2.2762  0.0447\n",
      "    270        1.5431        2.2747  0.0474\n",
      "    271        \u001b[36m1.5363\u001b[0m        2.2703  0.0361\n",
      "    272        \u001b[36m1.5302\u001b[0m        2.2885  0.0442\n",
      "    273        1.5336        2.2901  0.0363\n",
      "    274        1.5489        2.2633  0.0403\n",
      "    275        1.5480        2.2638  0.0425\n",
      "    276        1.5320        2.2860  0.0606\n",
      "    277        \u001b[36m1.5265\u001b[0m        2.2816  0.0581\n",
      "    278        1.5495        2.2719  0.0454\n",
      "    279        1.5438        2.2650  0.0392\n",
      "    280        1.5450        2.2913  0.0404\n",
      "    281        1.5379        2.2719  0.0378\n",
      "    282        1.5313        2.2636  0.0346\n",
      "    283        1.5319        2.2940  0.0400\n",
      "    284        \u001b[36m1.5210\u001b[0m        2.2731  0.0425\n",
      "    285        1.5242        2.2902  0.0381\n",
      "    286        \u001b[36m1.5197\u001b[0m        2.2851  0.0375\n",
      "    287        \u001b[36m1.5184\u001b[0m        2.2918  0.0360\n",
      "    288        \u001b[36m1.5183\u001b[0m        2.2785  0.0408\n",
      "    289        \u001b[36m1.5130\u001b[0m        2.2764  0.0429\n",
      "    290        1.5191        2.2744  0.0399\n",
      "    291        1.5177        2.2862  0.0506\n",
      "    292        1.5166        2.2761  0.0659\n",
      "    293        1.5144        2.2761  0.0658\n",
      "    294        \u001b[36m1.5081\u001b[0m        2.2908  0.0580\n",
      "    295        1.5162        2.2631  0.0447\n",
      "    296        1.5172        2.2716  0.0385\n",
      "    297        1.5160        2.3026  0.0376\n",
      "    298        1.5125        2.2621  0.0440\n",
      "    299        1.5167        2.2791  0.0453\n",
      "    300        \u001b[36m1.5026\u001b[0m        2.3101  0.0472\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.regressor.NeuralNetRegressor'>[initialized](\n",
       "  module_=Net(\n",
       "    (input_layer): Linear(in_features=10, out_features=20, bias=True)\n",
       "    (hidden1): Linear(in_features=20, out_features=10, bias=True)\n",
       "    (output): Linear(in_features=10, out_features=1, bias=True)\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skorch import NeuralNetRegressor\n",
    "test_net2 = Net(20,10)\n",
    "# test_net2.apply(init_weights)\n",
    "nett2 = NeuralNetRegressor(test_net2, max_epochs=300,\n",
    "                          lr=0.01,\n",
    "                          batch_size=128,\n",
    "                          optimizer=optim.SGD,\n",
    "                          optimizer__momentum=0.8,\n",
    "#                           optimizer__weight_decay=0.0001,\n",
    "                          optimizer__nesterov = True,\n",
    "                          criterion=MEE)\n",
    "# Training\n",
    "nett2.fit(Xtrain, ytrain2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "prova1 = nett1.predict(Xval)\n",
    "prova2 = nett2.predict(Xval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = np.append(prova1, prova2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5971928"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_euclidean_error(pr, yval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f356b2d7d30>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(pr[:,0], pr[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-project",
   "language": "python",
   "name": "ml-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
